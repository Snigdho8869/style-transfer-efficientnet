# style-transfer-efficientnet

Neural Style Transfer is a deep learning technique that merges the style of one image with the content of another, creating a new, stylized image. This repository provides an implementation of Neural Style Transfer using pre-trained convolutional neural networks and an optimization algorithm. The implementation is based on TensorFlow and can be used for a variety of artistic and creative applications.


# Requirements:

* Python 3

* TensorFlow 2

* NumPy

* Matplotlib

* PIL 


# Examples:

<img align="right" alt="art" width="1000" src="https://i.ibb.co/Y2vXNqg/Screenshot-3.png">

<img align="right" alt="art" width="1000" src="https://i.ibb.co/Qdqhb5K/Screenshot-4.png">

<img align="right" alt="art" width="1000" src="https://i.ibb.co/NN1Qzh7/Screenshot-5.png">


# Webapplication:

This web application of neural style transfer allows users to upload their own images and apply various pre-defined styles to them, creating a new, stylized image. This application is built using a combination of web development technologies and deep learning frameworks. The user interface allows users to easily upload their images, select the style they want to apply. This application then uses a pre-trained convolutional neural network to extract feature representations from the images and an optimization algorithm to merge the features of the content and style images into a new, stylized output. 


# Webapplication Interface:
<img align="right" alt="interface" width="1000" src="https://i.ibb.co/JvcCwBx/Screenshot-2.png">

# Webapplication Result:
<img align="right" alt="interface" width="1000" src="https://i.ibb.co/hmMLNB5/Screenshot-1.png">


# Conclusion:

 Neural Style Transfer is a powerful deep learning technique that allows us to merge the style of one image with the content of another, creating a new, stylized image. The technique has a wide range of artistic and creative applications and can be used for generating unique social media content,  creating custom designs for products or merchandise.
